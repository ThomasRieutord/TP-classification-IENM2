{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAVAUX PRATIQUES DE CLASSIFICATION NON-SUPERVISEE\n",
    "==============================================\n",
    "\n",
    "Ces travaux pratiques ont pour but d’appliquer et de manipuler les différents algorithmes de classification vus en cours de de classification non supervisée. Le cas d’application est l’identification des régions homogènes en terme de température, à l’échelle climatique. Pour cela, nous disposons de 10 ans de mesures (de 1990 à 2000) journalières des température minimales (Tn) et maximales (Tx) sur 83 stations réparties sur la France métropolitaine.\n",
    "\n",
    "Enseignant : Thomas Rieutord (thomas.rieutord@meteo.fr)\n",
    "\n",
    "Travail demandé :\n",
    "-----------------\n",
    "En suivant le sujet de TP qui vous a été donné, compléter les cellules vides de ce notebook, aux endroits marqués par ###### afin de répondre aux questions.\n",
    "A la fin du TP, vous devriez pouvoir exécuter l'ensemble du programme en redémarrant et exécutant le notebook : `Noyau > Redémarrer & tout exécuter`.\n",
    "Vous pouvez aussi exporter le notebook en programme Python, lequel devrait tourner en tapant la commande `python3 TP_classification_IENM2.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions préliminaires\n",
    "------------------------\n",
    "  1. Que va-t-on classer ? Quels sont les prédicteurs ?\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. En déduire le nombre N d’individus et le nombre p de prédicteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. Doit-on normaliser les données ? Si oui, comment ? Si non, pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction et mise en forme des données\n",
    "-------------------------------\n",
    "Le fichier `../data/TN-TX-83stations.txt` contient les Tn et Tx de 83 stations météo stockées sous la forme suivante :\n",
    "```\n",
    "  DATE STATION1-TN STATION1-TX STATION2-TN STATION2-TX ... STATION83-TN STATION83-TX\n",
    "  jour1   valeurTN  valeurTX ... valeurTN  valeurTX \n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import coupdepouce as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile=\"../data/TN-TX-83stations_points.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction\n",
    "Ouvrir le fichier avec un éditeur de texte. Repérer les éléments séparateurs, la taille de l’en-tête et la nature des données (réel, entiers…).\n",
    "\n",
    "En déduire la commande pour importer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec Numpy\n",
    "alldata_np = ######\n",
    "print(\"Retourne un \",type(alldata_np),\" de taille \",np.shape(alldata_np))\n",
    "\n",
    "# Avec Pandas\n",
    "alldata_pd = ######\n",
    "print(\"Retourne un \",type(alldata_pd),\" de taille \",np.shape(alldata_pd))\n",
    "\n",
    "print(\"\\nComparaison ?\\t alldata_pd.values est un \",type(alldata_pd.values),\" de taille \",np.shape(alldata_pd.values))\n",
    "print(\"\\t\\t max(|pd.Dataframe.values - np.array|)=\",np.max(np.abs(alldata_pd.values-alldata_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du dataframe dans le notebook\n",
    "alldata_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en forme\n",
    "\n",
    "Les données que nous avons contiennent les TN et les TX mais nous souhaitons faire une classification seulement sur les TN.\n",
    "De plus, pour faire une classification, on mettre les données dans une matrice de profil `(n_individus, n_predicteurs)`.\n",
    "Pour les deux variables issues de l'extraction, `alldata_np` et `alldata_pd`, il est possible d'extraire les TN au format voulu en une seule ligne.\n",
    "\n",
    "En sélectionnant judicieusement les indices (slicing), extraire les séries temporelles de Tn pour toutes les stations dans une matrice nommée `TN`. S'assurer qu'elle est bien de profil `(n_individus, n_predicteurs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en forme : extraction des TN dans une matrice (n_individus, n_predicteurs)\n",
    "\n",
    "# Depuis Numpy\n",
    "TN=######\n",
    "# Depuis Pandas\n",
    "TN=######\n",
    "\n",
    "N,p = np.shape(TN)\n",
    "print(\"On dispose maintenant d'un jeu de données avec \",N,\"individus et \",p,\"prédicteurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS : extraire la matrice TN dans un dataframe et non un numpy.array\n",
    "\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPER BONUS : créer un dataframe qui\n",
    "# contienne la matrice TN (avec les colonnes correctement nommées)\n",
    "# et indexée par la date (et non entier qui ressemble à une date)\n",
    "\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien y a-t-il de données manquantes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de données manquantes\n",
    "nb_missingVal = ######\n",
    "print(\"Nombre de données manquantes=\",nb_missingVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification hierarchique ascendante\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import du package scipy.cluster.hierarchy\n",
    "from scipy.cluster import hierarchy as cha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critère de Ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de connexion ('linkage matrix') -> cha.linkage\"\n",
    "\n",
    "linkageMatrix=######\n",
    "\n",
    "print(\"Retourne un \",type(linkageMatrix),\" de taille \",np.shape(linkageMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé du dendrogramme -> cha.dendrogram\n",
    "\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "plt.figure(figsize=figsize)\n",
    "plt.title(u\"Dendrogramme (critère de Ward)\")\n",
    "######\n",
    "plt.ylabel(u\"Distance cophénétique\")\n",
    "plt.xlabel(\"Stations\")\n",
    "plt.show(block=False)\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix de K par examen de la distance cophénétique (3e colonne de la matrice de connexion)\n",
    "\n",
    "distance_cophenetique = ######\n",
    "\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "plt.figure(figsize=figsize)\n",
    "plt.title(u\"Croissance de la distance cophénétique (Ward)\")\n",
    "plt.bar(np.arange(linkageMatrix.shape[0],0,-1),distance_cophenetique,0.5)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.ylabel(u\"Distance cophénétique\")\n",
    "plt.xlabel(\"Nombre de classes\")\n",
    "plt.show(block=False)\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**?** D’après ces deux graphiques, quels nombres de classes semblent pertinents ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formation des groupes -> cha.fcluster\n",
    "\n",
    "K=######\n",
    "labels_ward=######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critère du saut minimum\n",
    "\n",
    "Répétez les même opérations que pour le critère de Ward. Nous allons ensuite comparer les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de connexion ('linkage matrix') -> cha.linkage\"\n",
    "\n",
    "linkageMatrix=######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé du dendrogramme-> cha.dendrogram\n",
    "\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(u\"Dendrogramme (saut minimum)\")\n",
    "######\n",
    "plt.ylabel(u\"Distance cophénétique\")\n",
    "plt.xlabel(\"Stations\")\n",
    "plt.show(block=False)\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix de K par examen de la distance cophénétique (3e colonne de la matrice de connexion)\n",
    "\n",
    "distance_cophenetique = ######\n",
    "\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "plt.figure(figsize=figsize)\n",
    "plt.title(u\"Croissance de la distance cophénétique (saut minimum)\")\n",
    "plt.bar(np.arange(linkageMatrix.shape[0],0,-1),distance_cophenetique,0.5)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.ylabel(u\"Distance cophénétique\")\n",
    "plt.xlabel(\"Nombre de classes\")\n",
    "plt.show(block=False)\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**?** Quelles différences observez-vous\n",
    "  * sur le dendrogramme ;\n",
    "  * sur la distance cophénétique ;\n",
    "  * sur le nombre de classes à retenir ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**?** Quel critère (entre Ward et saut minimum) vous semble le plus approprié ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des classes\n",
    "-----------------------------\n",
    "\n",
    "Nous avons maintenant une classification des stations suivant leur température minimale. Pour la commenter, il est important de pouvoir se représenter correctement ces classes. Nous cherchons ici à identifier des climats différents selon la région. On va donc regarder d’une part le cycle annuel des Tn pour le point moyen de chaque cluster et d’autre part positionner les stations avec leur classe sur une carte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_ward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle annuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition de la colormap (permet d'attribuer toujours la même couleur dans différents graphiques)\n",
    "colmap=cm.nipy_spectral(np.arange(K)/K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des moyennes mensuelles -> pandas.groupby\n",
    "mois_en3lettres = ['Jan','Fev','Mar','Avr','Mai','Jun','Juil','Aou','Sep','Oct','Nov','Dec']\n",
    "\n",
    "TN_pd = cp.solution_bonus1(alldata_pd)\n",
    "moyenne_mensuelle = ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les moyennes mensuelles par cluster\n",
    "moyenne_mensuelle_par_cluster = np.zeros((K,12))\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "plt.figure(figsize=figsize)\n",
    "plt.title(\"Cycle annuel pour chaque cluster\")\n",
    "for k in range(K):\n",
    "    plt.plot(\n",
    "        mois_en3lettres,\n",
    "        moyenne_mensuelle_par_cluster[k,:],\n",
    "        color=colmap[k],\n",
    "        label='Cluster '+str(k+1),\n",
    "        linewidth=2\n",
    "    )\n",
    "plt.ylabel(\"TN\")\n",
    "plt.xlabel(\"Mois\")\n",
    "plt.legend(loc='best')\n",
    "plt.show(block=False)\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur une carte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des coordonnées des stations\n",
    "\n",
    "coordFile=\"../data/coord-83stations_points.txt\"\n",
    "\n",
    "# Avec Pandas\n",
    "coords = ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.img_tiles as cimgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé de la carte...\n",
    "\n",
    "stamen_terrain = cimgt.StamenTerrain()\n",
    "minlon,maxlon,minlat,maxlat = (-6.3, 11.5, 41.8, 51.2)\n",
    "\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=stamen_terrain.crs)\n",
    "ax.set_extent([minlon,maxlon,minlat,maxlat], crs=ccrs.Geodetic())\n",
    "\n",
    "# Add the Stamen data. Start at zoom level 3, then try 6.\n",
    "ax.add_image(stamen_terrain, 6)\n",
    "\n",
    "resolution = '50m'\n",
    "ax.add_feature(\n",
    "    cfeature.NaturalEarthFeature('cultural', 'admin_0_countries', resolution, edgecolor='black', facecolor='none')\n",
    ")\n",
    "\n",
    "ax.scatter(\n",
    "    coords.lon,\n",
    "    coords.lat,\n",
    "    marker='o',\n",
    "    c=cm.nipy_spectral((labels-1)/K),\n",
    "    s=60,\n",
    "    alpha=0.7,\n",
    "    transform=ccrs.Geodetic()\n",
    ")\n",
    "\n",
    "plt.show(block=False)\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASSIFICATION EN PARTITIONS\n",
    "======================================================================\n",
    "\n",
    "4.1 K-means\n",
    "---------------------------------------------------\n",
    "Il existe deux packages pour utiliser les K-means : `pyclustering` et `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclustering.cluster.kmeans import kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prend K points de l'echantillon que l'on perturbe\n",
    "init_medoids=TN[np.random.choice(N,K,replace=False),:]+2*np.random.sample(p)-1\n",
    "\n",
    "# Créer une instance de Kmeans\n",
    "km_pyclust = ######\n",
    "\n",
    "# Effectuer les calculs\n",
    "######\n",
    "\n",
    "# Récupérer les clusters\n",
    "clusters_km_pyclust = ######\n",
    "print(\"Kmeans (pyclustering) retourne \",type(clusters_km_pyclust),\"de taille\",len(clusters_km_pyclust))\n",
    "\n",
    "# Transformation en labels (à la main)\n",
    "labels_km_pyclust = np.zeros(N)\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_init=20\n",
    "\n",
    "# Créer une instance de Kmeans\n",
    "km_spy = ######\n",
    "\n",
    "# Effectuer les calculs\n",
    "######\n",
    "\n",
    "# Récupérer les labels\n",
    "labels_km_spy = ######\n",
    "print(\"Kmeans (scipy) retourne \",type(labels_km_spy),\"de taille\",len(labels_km_spy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 K-medoids\n",
    "--------------------------------------------------\n",
    "Les K-medoids ne sont pas (encore) disponible dans `scikit-learn`.\n",
    "Ils le sont dans une extension non-officielle et dans `pyclustering`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclustering.cluster.kmedoids import kmedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des points de départ (aléatoire)\n",
    "init_medoids=np.random.choice(N,K,replace=False)\n",
    "print(u\"Choix des points de départ (aléatoire) : \",K,\"points de l'échantillon. Indices :\",init_medoids)\n",
    "\n",
    "# Créer une instance de Kmedoids\n",
    "pam = ######\n",
    "\n",
    "# Effectuer les calculs\n",
    "######\n",
    "\n",
    "# Récupérer les clusters\n",
    "clusters_pam = ######\n",
    "\n",
    "print(\"Kmedoids (pyclustering) retourne \",type(clusters_pam),\"de taille\",len(clusters_pam))\n",
    "\n",
    "# Transformation en labels\n",
    "labels_pam = np.zeros(N)\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Calcul des silhouettes\n",
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_pam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour le tracé des silhouettes (donnée)\n",
    "cp.plot_silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du score de silhouette -> sklearn.metrics.silhouette_score\n",
    "silhouette_values = ######\n",
    "print(\"Retourne un\",type(silhouette_values),\" de taille \",silhouette_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du score de silhouette -> sklearn.metrics.silhouette_score\n",
    "sil_score = ######\n",
    "print(\"Retourne un\",type(sil_score),\" de valeur \",sil_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.plot_silhouette(silhouette_values, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour visualiser les clusters, réexécuter les cellules dédiées avec `labels=labels_km_spy` (par exemple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deverrouillage de la correction\n",
    "--------------------------------------------\n",
    "Pour déverrouiller le notebook qui contient la correction, il vous faudra utiliser la commande `gpg correction.ipynb`.\n",
    "Une phrase de passe vous sera demandée.\n",
    "Il s'agit du score de silhouette obtenu avec le critère de Ward, avec 6 décimales..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
